python3.9 -m federated_ppo.main \
    --env-type=atari \
    --gym-id=BeamRiderNoFrameskip-v4 \
    --exp-name=collaborative_penalty_comparison \
    --setup-id=comm_penalty_coeff_5.0 \
    --policy-aggregation-mode=average_return \
    --n-agents=3 \
    --total-timesteps=10000000 \
    --local-updates=16 \
    --seed=0 \
    --objective-mode=3 \
    --use-comm-penalty=True \
    --comm-penalty-coeff=5.0 \
    --learning-rate=2.5e-4 \
    --capture-video=True \
    --track=True \
    --wandb-project-name=FedRL_BeamRiderNoFrameskip-v4

python3.9 -m federated_ppo.main \
    --env-type=atari \
    --gym-id=BeamRiderNoFrameskip-v4 \
    --exp-name=collaborative_penalty_comparison \
    --setup-id=comm_penalty_coeff_10.0 \
    --policy-aggregation-mode=average_return \
    --n-agents=3 \
    --total-timesteps=10000000 \
    --local-updates=32 \
    --seed=0 \
    --objective-mode=3 \
    --use-comm-penalty=True \
    --comm-penalty-coeff=10.0 \
    --learning-rate=2.5e-4 \
    --capture-video=True \
    --track=True \
    --wandb-project-name=FedRL_BeamRiderNoFrameskip-v4

python3.9 -m federated_ppo.main \
    --env-type=atari \
    --gym-id=BeamRiderNoFrameskip-v4 \
    --exp-name=collaborative_penalty_comparison \
    --setup-id=comm_penalty_coeff_2.0 \
    --policy-aggregation-mode=average_return \
    --n-agents=3 \
    --total-timesteps=10000000 \
    --local-updates=64 \
    --seed=0 \
    --objective-mode=3 \
    --use-comm-penalty=True \
    --comm-penalty-coeff=2.0 \
    --learning-rate=2.5e-4 \
    --capture-video=True \
    --track=True \
    --wandb-project-name=FedRL_BeamRiderNoFrameskip-v4

